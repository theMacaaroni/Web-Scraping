{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5185b2a",
   "metadata": {},
   "source": [
    "# Web Scraping using *BeautifulSoup* and *requests*\n",
    "## **Introduction**\n",
    "In this project, we will use the modules `BeautifulSoup` and `requests` to showcase an introduction to web scraping, the automated process of collecting data from websites. \n",
    "\n",
    "The `requests` module is used to make a *request* to a web server, which downloads the HTML content of a given web page.\n",
    "\n",
    "HTML (HyperText Markup Language) is a markup language that tells a browser how to display content. \n",
    "\n",
    "The `BeautifulSoup` module is then used to *parse* the downloaded HTML data from the web page and extract the desired content. \n",
    "\n",
    "Finally, the `pandas` module will be used to extract the data into a dataframe for future analysis.\n",
    "\n",
    "Generally, we will follow these steps to extract data from a website:\n",
    "\n",
    "    Request the source code of a specific URL\n",
    "    Download returned content\n",
    "    Identify the elements of the page we want\n",
    "    Extract those elements into dataset\n",
    "\n",
    "Let us begin by importing the appropriate libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163546d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e332d41",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "In this first scrape, we will be using the online encyclopedia, *Wikipedia*, to extract a list of champions from the racing sport *Formula 1*.\n",
    "\n",
    "A good start to scraping begins with a static website so as to not overwhelm the complexity of the code.\n",
    "\n",
    "The `requests` module is used to submit a `GET` request to the Wikipedia page that downloads the HTML content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79dd6320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_Formula_One_World_Drivers%27_Champions\"\n",
    "page = requests.get(url)\n",
    "print(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df59073b",
   "metadata": {},
   "source": [
    "The response object returned contains a status code indicating whether our download was successful or not.\n",
    "\n",
    "Generally, response codes starting with `2` indicate success, and codes starting with `4` or `5` indicate an error has occured.\n",
    "\n",
    "Next, an instance of the *BeautifulSoup* class will be created and the document can be parsed and prepared for data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54cd3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = bs(page.content, \"html.parser\") # .content prints out the HTML content of the web page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b395b",
   "metadata": {},
   "source": [
    "Using developer tools provided by web browsers helps us to easily navigate the HTML of a web page directly on itself. This can be done using the *inspect* tool on a given portion of a web page. \n",
    "\n",
    "BeautifulSoup also contains a method that prints out the HTML in a structured format called `prettify()` which we will not be using here but is shown for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7aeeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify())\n",
    "# We will opt to use the developer tools on the website itself (inspect) to navigate the HTML instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961441e",
   "metadata": {},
   "source": [
    "### Finding all instances of a tag at once\n",
    "We are looking to extract the *World Driver's Champions by season* table from the Wikipedia page. \n",
    "\n",
    "We can use the `.find_all()` method to find all instances of tables using the appropriate *tag*.\n",
    "\n",
    "**Tags** are important elements that make up an HTML document and allows us to navigate through and extract other tags and text.\n",
    "\n",
    "Let us find all instances of tables on this web page using the `table` tag. Note that the `find_all()` method returns a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf26bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(soup.find_all('table')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b89a026",
   "metadata": {},
   "source": [
    "There are 14 returned instances of the `table` tag within this document, but we are looking for just the one. \n",
    "### Searching for tags by class\n",
    "Classes (and ids) are used to determine which HTML elements to apply certain styles to. With the help of the developer tools, we can leverage this and also use them to specify the elements we want to scrape.\n",
    "\n",
    "We see that the table has a \"wikitable sortable\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc81134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(soup.find_all(\"table\", class_ = \"wikitable sortable\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de15929",
   "metadata": {},
   "source": [
    "We cut down the number of instances by half but again this still produces a lot of undesired data. \n",
    "\n",
    "Recall that find_all() returns a list and we can use list indexing to partition the slice of data we want. \n",
    "\n",
    "In this case, we want the first entry as that table is what contains all our desired info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8652cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = soup.find_all(\"table\", class_ = \"wikitable sortable\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62868597",
   "metadata": {},
   "source": [
    "### Searching using CSS selectors\n",
    "Items can also be found using CSS selectors. These selectors are how the CSS language allows developers to specify HTML tags to style. Here are some examples:\n",
    "\n",
    "    div p — finds all p tags inside of a div tag.\n",
    "    body p a — finds all a tags inside of a p tag inside of a body tag.\n",
    "    html body — finds all body tags inside of an html tag.\n",
    "    p.outer-text — finds all p tags with a class of outer-text.\n",
    "    p#first — finds all p tags with an id of first.\n",
    "    body p.outer-text — finds any p tags with a class of outer-text inside of a body tag.\n",
    "### Extracting the column names\n",
    "At first glance, we see that the column names are stored in `th` tags within `tr` tags. \n",
    "\n",
    "We'll use CSS selectors to extract the column names from the `tr` tag.\n",
    "\n",
    "(This section needs refining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ac19a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Season', 'Driver', 'Age', 'Constructor', 'Tyres', 'Poles', 'Wins', 'Podiums', 'Fastest laps', 'Points', '% Points', 'Clinched[17]', '# of racesremaining', 'Margin', '% Margin', 'Chassis', 'Engine', 'Season', 'Driver', 'Age', 'Chassis', 'Engine', 'Tyres', 'Poles', 'Wins', 'Podiums', 'Fastest laps', 'Points', '% Points', 'Clinched', '# of racesremaining', 'Margin', '% Margin', 'Constructor']\n"
     ]
    }
   ],
   "source": [
    "cols = [t.get_text().strip() for t in c_list.select(\"tr th\")]\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd76bc8",
   "metadata": {},
   "source": [
    "We extracted the desired columns, but we also extracted duplicated values.\n",
    "\n",
    "Upon closer inspection, we see that our desired column names are in two locations, the `thead` and `tfoot` tag. \n",
    "\n",
    "Looking at the table, we notice that the *Constructors* column is really two columns in one. \n",
    "\n",
    "The `tfoot` tag does the honors of splitting them into individual columns, so we will extract from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b71605bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Season', 'Driver', 'Age', 'Chassis', 'Engine', 'Tyres', 'Poles', 'Wins', 'Podiums', 'Fastest laps', 'Points', '% Points', 'Clinched', '# of racesremaining', 'Margin', '% Margin']\n"
     ]
    }
   ],
   "source": [
    "# Prints desired names but has empty strings with it\n",
    "cols = [t.get_text().strip() for t in c_list.select(\"tr\")[-2]]\n",
    "\n",
    "# Removes all empty strings since blank strings evaluate to false in a boolean context\n",
    "cols[:] = [x for x in cols if x]\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba3279",
   "metadata": {},
   "source": [
    "### Extracting information from the table\n",
    "Now that we have the appropriate columns, we will begin to scrape the page to populate them.\n",
    "\n",
    "The data we want is located within the `tr` tags of `c_list`.\n",
    "\n",
    "Each `tr` tag contains the information that is required to populate one row of our dataframe in individual `td` tags.\n",
    "\n",
    "Let's find all instances of the `tr` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489ce3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_info = c_list.select(\"tr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f71a6",
   "metadata": {},
   "source": [
    "We now have a list of the individual `tr` tags that contain the information needed. \n",
    "\n",
    "We must be careful, however, as the first two and last two indicies contain information from `thead` and `tfoot` tag that also have `tr` tags. We will remove these for now and move forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8334323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_info = f1_info[2:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e21930",
   "metadata": {},
   "source": [
    "The desired information has been organized but we now need to isolate individual data for each column that is stored within the `td` tags. \n",
    "\n",
    "The `td` tags are nested, so we can select all the elements using the `children` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca85f90e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_list = [] # Initiate empty list to store each champion entry\n",
    "\n",
    "for element in f1_info:\n",
    "\n",
    "    f1_champ = []\n",
    "    \n",
    "    for tag in element.children:\n",
    "        \n",
    "        f1_champ.append(tag.get_text().strip()) # Appends extracted, stripped text from each individual <td> tag  \n",
    "        \n",
    "    f1_champ[:] = [x for x in f1_champ if x] # Removes any blank strings within the list\n",
    "    \n",
    "    f1_list.append(f1_champ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73724ba9",
   "metadata": {},
   "source": [
    "### Creating Dataframe\n",
    "We previously obtained all the names of the columns we are interested in, stored in `cols`. \n",
    "\n",
    "We now have extracted the information for each champion, stored in `f1_list`.\n",
    "\n",
    "Let us finish by creating a dataframe containing our desired information. \n",
    "\n",
    "This step could also include exporting our data into a csv file for others to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ceba1a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Driver</th>\n",
       "      <th>Age</th>\n",
       "      <th>Chassis</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Tyres</th>\n",
       "      <th>Poles</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Podiums</th>\n",
       "      <th>Fastest laps</th>\n",
       "      <th>Points</th>\n",
       "      <th>% Points</th>\n",
       "      <th>Clinched</th>\n",
       "      <th># of racesremaining</th>\n",
       "      <th>Margin</th>\n",
       "      <th>% Margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950</td>\n",
       "      <td>Giuseppe Farina[20]</td>\n",
       "      <td>44</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>P</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>83.333 (47.619)</td>\n",
       "      <td>Race 7 of 7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951</td>\n",
       "      <td>Juan Manuel Fangio[21]</td>\n",
       "      <td>40</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>P</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>86.111 (51.389)</td>\n",
       "      <td>Race 8 of 8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952[a]</td>\n",
       "      <td>Alberto Ascari[23]</td>\n",
       "      <td>34</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>F P</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>100.000 (74.306)</td>\n",
       "      <td>Race 6 of 8</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>33.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953[a]</td>\n",
       "      <td>Alberto Ascari[23]</td>\n",
       "      <td>35</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>P</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>34.5</td>\n",
       "      <td>95.833 (57.764)</td>\n",
       "      <td>Race 8 of 9</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>18.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954</td>\n",
       "      <td>Juan Manuel Fangio[21]</td>\n",
       "      <td>43</td>\n",
       "      <td>Maserati[b]</td>\n",
       "      <td>Maserati</td>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>93.333 (70.547)</td>\n",
       "      <td>Race 7 of 9</td>\n",
       "      <td>2</td>\n",
       "      <td>16.857</td>\n",
       "      <td>40.136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season                  Driver Age      Chassis      Engine Tyres Poles  \\\n",
       "0     1950     Giuseppe Farina[20]  44   Alfa Romeo  Alfa Romeo     P     2   \n",
       "1     1951  Juan Manuel Fangio[21]  40   Alfa Romeo  Alfa Romeo     P     4   \n",
       "2  1952[a]      Alberto Ascari[23]  34      Ferrari     Ferrari   F P     5   \n",
       "3  1953[a]      Alberto Ascari[23]  35      Ferrari     Ferrari     P     6   \n",
       "4     1954  Juan Manuel Fangio[21]  43  Maserati[b]    Maserati     P     5   \n",
       "\n",
       "  Wins Podiums Fastest laps Points          % Points     Clinched  \\\n",
       "0    3       3            3     30   83.333 (47.619)  Race 7 of 7   \n",
       "1    3       5            5     31   86.111 (51.389)  Race 8 of 8   \n",
       "2    6       6            6     36  100.000 (74.306)  Race 6 of 8   \n",
       "3    5       5            4   34.5   95.833 (57.764)  Race 8 of 9   \n",
       "4    6       7            3     42   93.333 (70.547)  Race 7 of 9   \n",
       "\n",
       "  # of racesremaining  Margin % Margin  \n",
       "0                   0       3   10.000  \n",
       "1                   0       6   19.355  \n",
       "2                   2      12   33.333  \n",
       "3                   1     6.5   18.841  \n",
       "4                   2  16.857   40.136  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = pd.DataFrame(f1_list, columns = cols)\n",
    "# f1.to_csv()\n",
    "f1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a172b7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we have succesfully scraped the *World Driver's Champions by season* table from Wikipedia using the `requests`, `BeautifulSoup`, and `pandas` modules. \n",
    "\n",
    "The techniques used within this project showcased an introduction to scraping of a static website. \n",
    "\n",
    "Improvements can be made surrounding the extraction and handling of tags for ease of complexity. \n",
    "\n",
    "Future endeavors will be to create functions and scrape dynamic websites. \n",
    "\n",
    "We will return at a later time to conduct exploration, cleaning and analysis of the data we just obtained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
